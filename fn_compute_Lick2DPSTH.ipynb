{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datajoint as dj\n",
    "img= dj.schema('arseny_learning_imaging', locals())\n",
    "imgframstarttrail1= dj.VirtualModule('IMG', 'arseny_learning_imaging')\n",
    "imgframstarttrail= imgframstarttrail1.IMG.FramStartTrail\n",
    "\n",
    "tracking= dj.schema('arseny_learning_tracking', locals())\n",
    "tracking= dj.VirtualModule('TRACKING', 'arseny_learning_tracking')\n",
    "grooming= tracking.VideoGroomingTrail\n",
    "\n",
    "exp2= dj.schema('arseny_s1alm_experiment2', locals())\n",
    "exp2vm= dj.VirtualModule ('EXP2', 'arseny_s1alm_experiment2')\n",
    "behaviortrail= exp2vm.BehaviorTrial\n",
    "behaviortrailevent= exp2vm.BehaviorTrailEvent\n",
    "actionevent= exp2vm.ActionEvent\n",
    "\n",
    "lick2dtalp= dj.schema('talch012_lick2dtalp', locals())\n",
    "lick2dtal= dj.VirtualModule('Lick2DtalP', 'talch012_lick2dtalp')\n",
    "\n",
    "from fn_parse_into_trials_and_get_lickrate_tal_1 import fn_parse_into_trials_and_get_lickrate_tal_1\n",
    "from lick2dtalp.ROILick2DPSTHSpikes import rel_data, rel_temp, flag_eletric_video, fr_interval_limit, fr_interval, time_resample_bin \n",
    "# real_data comes from img.roispike that has the key 'spikes_trace'= deconvolved trace for each frame\n",
    "\n",
    "# discard the first and last trails\n",
    "# session epoch trail comes from the table in the same name that describe behave only, behav photo, spint only and spont photo\n",
    "# whould it be esier to import the psth_mean_stem function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## table keys called in this function\n",
    "\n",
    "# IMG.ROI\n",
    "#   roi_number, roi_number_uid (=unique across sessions, special cell we are following throughout exp), roi_centroid_x,roi_centroid_y (=the intersect of the triangle medians x comp and y comp), roi_radius, roi_x_pix, roi_y_pix, roi_pixel_weight...\n",
    "# IMG.ROIBad\n",
    "#   bad ROI that were considered cell by suite2p\n",
    "# FOVEpoch\n",
    "#   imaging_fram_rate, \"_\"_\"_plane, \"_\"_\"_volume, zoom,imaging_fov_deg, imaging_fov_um\n",
    "# FOV\n",
    "#   fov_name, fov_x_size (=pixels), fov_y_size (=pixels), imaging_fram_rate (redundant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_computer_Lick2DPSTH(key, self, rel_data, fr_interval, fr_interval_limit, flag_electric_video, time_resample_bin, self2, self3, self4):\n",
    "    import numpy as np\n",
    "    import scipy as scipy\n",
    "    import scipy.stats\n",
    "    from scipy import signal\n",
    "    from scipy import stats as st\n",
    "    from scipy.stats import ranksums, pearsonr\n",
    "    from datajoint import fetch1, fetch, insert\n",
    "    \n",
    "    # frames for PSTH\n",
    "    smooth_window_sec = 0.2\n",
    "\n",
    "    # fetch data\n",
    "    rel_ROI = (img.ROI - img.ROIBad) & key # roi bad are bad ROI that were considered cell by suite2p\n",
    "    key_ROI1 = fetch(rel_ROI, order_by='roi_number')  # lick2dtalp.ROILick2DPSTHSpikes\n",
    "    key_ROI2 = fetch(rel_ROI, order_by='roi_number')  # lick2dtalp.ROILick2DPSTHStatsSpikes\n",
    "    key_ROI3 = fetch(rel_ROI, order_by='roi_number')  # lick2dtalp.ROILick2DPSTHBlockSpikes\n",
    "    key_ROI4 = fetch(rel_ROI, order_by='roi_number')  # lick2dtalp.ROILick2DPSTHBlockStatsSpikes\n",
    "    rel_data = rel_data & rel_ROI & key\n",
    "    try:\n",
    "        frame_rate = fetch1(img.FOVEpoch & key, 'imaging_frame_rate')\n",
    "    except:\n",
    "        frame_rate = fetch1(img.FOV & key, 'imaging_frame_rate')\n",
    "    smooth_window_frames = int(np.ceil(smooth_window_sec * frame_rate))  # frames for PSTH, Rounds toward positive infinity \n",
    "\n",
    "    # fetch trial data\n",
    "    R = fetch((exp2.TrialRewardSize & key) - tracking.VideoGroomingTrial, '*', order_by='trial') # It fetches the info from all the keys in the immediate table and all the primary keys from the parental tables -> from session trail it takes 'trail', from sessioms it takes 'session' and from subject it taks 'subject id' and excludes the times grooming obsreved\n",
    "    block = fetch((exp2.TrialLickBlock & key) - tracking.VideoGroomingTrial, '*', order_by='trial')\n",
    "    S = fetch(rel_data, '*') #rel_data comes from the table definition, it refers to ROISpikes (flourescent trace) that calculates the spikes_trace which is deconvolved trace for each frame \n",
    "    if 'spikes_trace' in S:  # to be able to run the code both on dff and on deconvulted \"spikes\" data\n",
    "        S['dff_trace'] = S['spikes_trace'] #dff_trace is a defined key\n",
    "        del S['spikes_trace']\n",
    "    \n",
    "    # parsing trials\n",
    "    start_file, end_file = fn_parse_into_trials_and_get_lickrate_tal_1(key, frame_rate, fr_interval, flag_electric_video)\n",
    "    start_file[-1], end_file[-1] = np.nan, np.nan  # we don't use the very last trial\n",
    "    num_trials = len(start_file)\n",
    "    idx_response = ~np.isnan(start_file)\n",
    "    \n",
    "    try:\n",
    "        # idx reward\n",
    "        #idx_regular = np.where(np.array([R['reward_size_type'] == 'regular' for trial in R]) & idx_response)[0]\n",
    "        idx_regular = np.where(np.array([R[i]['reward_size_type'] == 'regular' for i in range(num_trials)]) & idx_response)[0] # fond the index of regular, small and large \n",
    "        idx_regular_temp = np.array([R[i]['reward_size_type'] == 'regular' for i in range(num_trials)]) & idx_response # regular ind by 01 \n",
    "        idx_small = np.where(np.array([R[i]['reward_size_type'] == 'omission' for i in range(num_trials)]) & idx_response)[0]\n",
    "        idx_large = np.where(np.array([R[i]['reward_size_type'] == 'large' for i in range(num_trials)]) & idx_response)[0]\n",
    "        idx_odd_small = idx_small[::2][:len(idx_small)] # chooses the odd out of the small  from the regular \n",
    "        idx_even_small = idx_small[1::2][:len(idx_small)]\n",
    "        idx_odd_large = idx_large[::2][:len(idx_large)]\n",
    "        idx_even_large = idx_large[1::2][:len(idx_large)]\n",
    "    except:\n",
    "        idx_regular = np.where(np.arange(1, num_trials + 1) & idx_response)[0]\n",
    "        idx_regular_temp = np.arange(1, num_trials + 1)[idx_response]\n",
    "\n",
    "    idx_odd_regular = idx_regular[::2][:len(idx_regular)]\n",
    "    idx_even_regular = idx_regular[1::2][:len(idx_regular)]\n",
    "    \n",
    "    try\n",
    "        # devied the block to 4 bins according to the current_trial_number_in_block- the first trial are defined as first all the first trials, and the three others inbetween the bins values defined\n",
    "        # find the most frequent num_trials_in_block. in matlab we use mode(), in python we can use statistics.mode() but here we use bincount to count each value and returns the highest count value. note that in both (python&matlab) cases it returns the first mode he founds (meaning if you have two most freq values, it returns the first that appeared) \n",
    "        # we devied the regular but no small/large as regular are 80% of the data. \n",
    "        num_trials_in_block = np.bincount(block.num_trials_in_block).argmax()\n",
    "        begin_mid_end_bins = np.linspace(2, num_trials_in_block, 4)# returns 4 values the first is 2, the last is num_trials_in_block and the two middel ones are num_trials_in_block-(num_trials_in_block-2)/3 and ans-(num_trials_in_block-2)/3\n",
    "\n",
    "        idx_first = np.where((np.array(Block.current_trial_num_in_block) == 1) & idx_response & idx_regular_temp)[0] #indexes of the current trail in block==1&not nan& ind of the 01 map of regular reward\n",
    "        idx_begin = np.where((np.array(Block.current_trial_num_in_block) >= begin_mid_end_bins[0]) & (np.array(Block.current_trial_num_in_block) <= np.floor(begin_mid_end_bins[1])) & idx_response & idx_regular_temp)[0]\n",
    "        idx_mid = np.where((np.array(Block.current_trial_num_in_block) > begin_mid_end_bins[1]) & (np.array(Block.current_trial_num_in_block) <= np.round(begin_mid_end_bins[2])) & idx_response & idx_regular_temp)[0]\n",
    "        idx_end = np.where((np.array(Block.current_trial_num_in_block) > begin_mid_end_bins[2]) & (np.array(Block.current_trial_num_in_block) <= np.ceil(begin_mid_end_bins[3])) & idx_response & idx_regular_temp)[0]\n",
    "\n",
    "        idx_odd_first = idx_first[::2][np.in1d(idx_regular[::2], idx_first)]\n",
    "        idx_even_first = idx_first[1::2][np.in1d(idx_regular[1::2], idx_first)]\n",
    "\n",
    "        idx_odd_begin = idx_begin[::2][np.in1d(idx_regular[::2], idx_begin)]\n",
    "        idx_even_begin = idx_begin[1::2][np.in1d(idx_regular[1::2], idx_begin)]\n",
    "\n",
    "        idx_odd_mid = idx_mid[::2][np.in1d(idx_regular[::2], idx_mid)]\n",
    "        idx_even_mid = idx_mid[1::2][np.in1d(idx_regular[1::2], idx_mid)]\n",
    "\n",
    "        idx_odd_end = idx_end[::2][np.in1d(idx_regular[::2], idx_end)]\n",
    "        idx_even_end = idx_end[1::2][np.in1d(idx_regular[1::2], idx_end)]\n",
    "    except\n",
    "        # add an exception\n",
    "    \n",
    "    # we take the session epoch type and number of the current key (one iteration) and apply it to the coresponding possition in each key_ROI(i). we are going to use key_ROI for####\n",
    "    for i_roi in range(1, S.shape[0] + 1):\n",
    "    key_ROI1 = dict(session_epoch_type=key['session_epoch_type'], session_epoch_number=key['session_epoch_number'])\n",
    "    key_ROI2 = dict(session_epoch_type=key['session_epoch_type'], session_epoch_number=key['session_epoch_number'])\n",
    "    key_ROI3 = dict(session_epoch_type=key['session_epoch_type'], session_epoch_number=key['session_epoch_number'])\n",
    "    key_ROI4 = dict(session_epoch_type=key['session_epoch_type'], session_epoch_number=key['session_epoch_number'])\n",
    "\n",
    "    # Use key_ROI1, key_ROI2, key_ROI3, key_ROI4 as needed\n",
    "    # Perform further operations or insert into DataJoint tables\n",
    "\n",
    "    #PSTH \n",
    "    psth_all = [None] * len(i_tr)\n",
    "    spikes = S[i_roi]['dff_trace'] #spikes is the dff_trace of each row in S\n",
    "    # time_resample_bin is originated from the tables definition, and it is empty\n",
    "    if time_resample_bin is None:\n",
    "        for i_tr in range(len(start_file)):\n",
    "            if idx_response[i_tr] == 0:  # its an ignore trial\n",
    "                psth_all[i_tr] = None\n",
    "                continue\n",
    "        \n",
    "            s = spikes[start_file[i_tr]:end_file[i_tr]]\n",
    "            s = np.convolve(s, np.ones(smooth_window_frames) / smooth_window_frames, mode='valid')\n",
    "            # s_interval=s(time>fr_interval(1) & time<=fr_interval(2));\n",
    "            # fr_all(i_roi,i_tr)= max(s_interval); %taking the max\n",
    "            time = np.arange(1, len(s) + 1) / frame_rate + fr_interval[0]\n",
    "            psth_all[i_tr] = s\n",
    "    else:\n",
    "        time_new_bins = np.arange(fr_interval[0], fr_interval[-1], time_resample_bin)\n",
    "        time_new = time_new_bins[:-1] + np.mean(np.diff(time_new_bins)) / 2\n",
    "        for i_tr in range(len(start_file)):\n",
    "            if idx_response[i_tr] == 0:\n",
    "                psth_all[i_tr] = None\n",
    "                continue\n",
    "            s = spikes[start_file[i_tr]:end_file[i_tr]]\n",
    "            s = np.convolve(s, np.ones(smooth_window_frames) / smooth_window_frames, mode='valid')\n",
    "            time = np.arange(1, len(s) + 1) / frame_rate + fr_interval[0]\n",
    "            s_resampled = []\n",
    "            for i_t in range(len(time_new_bins) - 1):\n",
    "                idx_t = (time > time_new_bins[i_t]) & (time <= time_new_bins[i_t + 1])\n",
    "                s_resampled.append(np.mean(s[idx_t]))\n",
    "            psth_all[i_tr] = s_resampled\n",
    "        time = time_new\n",
    "\n",
    "\n",
    "    psth_regular = np.mean(np.concatenate(psth_all[idx_regular]), axis=0)\n",
    "    psth_regular_stem = np.std(np.concatenate(psth_all[idx_regular]), axis=0) / np.sqrt(len(idx_regular))\n",
    "    psth_regular_odd = np.nanmean(np.concatenate(psth_all[idx_odd_regular]), axis=0)\n",
    "    psth_regular_even = np.nanmean(np.concatenate(psth_all[idx_even_regular]), axis=0)\n",
    "\n",
    "    key_ROI1[i_roi].insert1({\n",
    "        'psth_regular': psth_regular,\n",
    "        'psth_regular_stem': psth_regular_stem,\n",
    "        'psth_regular_odd': psth_regular_odd,\n",
    "        'psth_regular_even': psth_regular_even,\n",
    "        'psth_time': time\n",
    "    })\n",
    "\n",
    "    # Calculating Pearson correlation for odd vs even to see if the data matches itself\n",
    "    r = np.corrcoef(psth_regular_odd, psth_regular_even)[0, 1]\n",
    "    key_ROI2[i_roi].insert1({'psth_regular_odd_vs_even_corr': r})\n",
    "\n",
    "    # Identifying the peak in the trace and when it occurred for the whole data\n",
    "    idx_peak = np.argmax(psth_regular)\n",
    "    key_ROI2[i_roi].insert1({'peaktime_psth_regular': time[idx_peak]})\n",
    "\n",
    "    idx_peak = np.argmax(psth_regular_odd)\n",
    "    key_ROI2[i_roi].insert1({'peaktime_psth_regular_odd': time[idx_peak]})\n",
    "\n",
    "    idx_peak = np.argmax(psth_regular_even)\n",
    "    key_ROI2[i_roi].insert1({'peaktime_psth_regular_even': time[idx_peak]})\n",
    "\n",
    "    try:\n",
    "        # Reward\n",
    "        # Taking the mean PSTH across trials\n",
    "        psth_small = np.nanmean(np.concatenate(psth_all[idx_small]), axis=0)\n",
    "        psth_small_stem = np.std(np.concatenate(psth_all[idx_small]), axis=0) / np.sqrt(len(idx_small))\n",
    "        psth_small_odd = np.nanmean(np.concatenate(psth_all[idx_odd_small]), axis=0)\n",
    "        psth_small_even = np.nanmean(np.concatenate(psth_all[idx_even_small]), axis=0)\n",
    "\n",
    "        psth_large = np.nanmean(np.concatenate(psth_all[idx_large]), axis=0)\n",
    "        psth_large_stem = np.std(np.concatenate(psth_all[idx_large]), axis=0) / np.sqrt(len(idx_large))\n",
    "        psth_large_odd = np.nanmean(np.concatenate(psth_all[idx_odd_large]), axis=0)\n",
    "        psth_large_even = np.nanmean(np.concatenate(psth_all[idx_even_large]), axis=0)\n",
    "\n",
    "        key_ROI1[i_roi].psth_small = psth_small\n",
    "        key_ROI1[i_roi].psth_small_stem = psth_small_stem\n",
    "        key_ROI1[i_roi].psth_small_odd = psth_small_odd\n",
    "        key_ROI1[i_roi].psth_small_even = psth_small_even\n",
    "\n",
    "        key_ROI1[i_roi].psth_large = psth_large\n",
    "        key_ROI1[i_roi].psth_large_stem = psth_large_stem\n",
    "        key_ROI1[i_roi].psth_large_odd = psth_large_odd\n",
    "        key_ROI1[i_roi].psth_large_even = psth_large_even\n",
    "\n",
    "\n",
    "        r = np.corrcoef(psth_small_odd, psth_small_even)[0, 1]\n",
    "        key_ROI2[i_roi].psth_small_odd_vs_even_corr = r\n",
    "\n",
    "        r = np.corrcoef(psth_large_odd, psth_large_even)[0, 1]\n",
    "        key_ROI2[i_roi].psth_large_odd_vs_even_corr = r\n",
    "\n",
    "        r = np.corrcoef(psth_regular, psth_small)[0, 1]\n",
    "        key_ROI2[i_roi].psth_regular_vs_small_corr = r\n",
    "\n",
    "        r = np.corrcoef(psth_regular, psth_large)[0, 1]\n",
    "        key_ROI2[i_roi].psth_regular_vs_large_corr = r\n",
    "\n",
    "        r = np.corrcoef(psth_small, psth_large)[0, 1]\n",
    "        key_ROI2[i_roi].psth_small_vs_large_corr = r\n",
    "\n",
    "\n",
    "        idx_peak_small = np.argmax(psth_small)\n",
    "        key_ROI2[i_roi].peaktime_psth_small = time[idx_peak_small]\n",
    "        idx_peak_regular = np.argmax(psth_regular)\n",
    "        key_ROI2[i_roi].peaktime_psth_regular = time[idx_peak_regular]\n",
    "        idx_peak_large = np.argmax(psth_large)\n",
    "        key_ROI2[i_roi].peaktime_psth_large = time[idx_peak_large]\n",
    "\n",
    "        # single trials, averaged across all time duration in a specific time interval (e.g. after the licport onset (t>=0))\n",
    "        idx_onset = (time >= fr_interval_limit[0]) & (time < fr_interval_limit[1])\n",
    "        temp = np.concatenate(psth_all[idx_regular])\n",
    "        psth_regular_trials = np.nanmean(temp[:, idx_onset], axis=1)\n",
    "        temp = np.concatenate(psth_all[idx_small])\n",
    "        psth_small_trials = np.nanmean(temp[:, idx_onset], axis=1)\n",
    "        temp = np.concatenate(psth_all[idx_large])\n",
    "        psth_large_trials = np.nanmean(temp[:, idx_onset], axis=1)\n",
    "\n",
    "        p_regular_small, _ = ranksum(psth_regular_trials, psth_small_trials)\n",
    "        key_ROI2[i_roi].reward_mean_pval_regular_small = p_regular_small\n",
    "        p_regular_large, _ = ranksum(psth_regular_trials, psth_large_trials)\n",
    "        key_ROI2[i_roi].reward_mean_pval_regular_large = p_regular_large\n",
    "        p_small_large, _ = ranksum(psth_small_trials, psth_large_trials)\n",
    "        key_ROI2[i_roi].reward_mean_pval_small_large = p_small_large\n",
    "\n",
    "        key_ROI2[i_roi].reward_mean_regular = np.nanmean(psth_regular_trials)\n",
    "        key_ROI2[i_roi].reward_mean_small = np.nanmean(psth_small_trials)\n",
    "        key_ROI2[i_roi].reward_mean_large = np.nanmean(psth_large_trials)\n",
    "\n",
    "        # at peak response time\n",
    "        temp = np.concatenate(psth_all[idx_regular])\n",
    "        psth_regular_trials_peak = temp[:, idx_peak_regular]\n",
    "        temp = np.concatenate(psth_all[idx_small])\n",
    "        psth_small_trials_peak = temp[:, idx_peak_small]\n",
    "        temp = np.concatenate(psth_all[idx_large])\n",
    "        psth_large_trials_peak = temp[:, idx_peak_large]\n",
    "\n",
    "        key_ROI2[i_roi].reward_peak_regular = np.nanmean(psth_regular_trials_peak)\n",
    "        key_ROI2[i_roi].reward_peak_small = np.nanmean(psth_small_trials_peak)\n",
    "        key_ROI2[i_roi].reward_peak_large = np.nanmean(psth_large_trials_peak)\n",
    "\n",
    "        p_peak_regular_small, _ = ranksum(psth_regular_trials_peak, psth_small_trials_peak)\n",
    "        key_ROI2[i_roi].reward_peak_pval_regular_small = p_peak_regular_small\n",
    "        p_peak_regular_large, _ = ranksum(psth_regular_trials_peak, psth_large_trials_peak)\n",
    "        key_ROI2[i_roi].reward_peak_pval_regular_large = p_peak_regular_large\n",
    "        p_peak_small_large, _ = ranksum(psth_small_trials_peak, psth_large_trials_peak)\n",
    "        key_ROI2[i_roi].reward_peak_pval_small_large = p_peak_small_large\n",
    "\n",
    "        # k2 = key_ROI3[i_roi]\n",
    "        # insert(self3, k2)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        # BLOCK\n",
    "        # Taking the mean PSTH across trials\n",
    "        psth_first = np.nanmean(np.concatenate(psth_all[idx_first]), axis=0)\n",
    "        psth_first_stem = np.std(np.concatenate(psth_all[idx_first]), axis=0) / np.sqrt(len(idx_first))\n",
    "        psth_first_odd = np.nanmean(np.concatenate(psth_all[idx_odd_first]), axis=0)\n",
    "        psth_first_even = np.nanmean(np.concatenate(psth_all[idx_even_first]), axis=0)\n",
    "\n",
    "        psth_begin = np.nanmean(np.concatenate(psth_all[idx_begin]), axis=0)\n",
    "        psth_begin_stem = np.std(np.concatenate(psth_all[idx_begin]), axis=0) / np.sqrt(len(idx_begin))\n",
    "        psth_begin_odd = np.nanmean(np.concatenate(psth_all[idx_odd_begin]), axis=0)\n",
    "        psth_begin_even = np.nanmean(np.concatenate(psth_all[idx_even_begin]), axis=0)\n",
    "\n",
    "        psth_mid = np.nanmean(np.concatenate(psth_all[idx_mid]), axis=0)\n",
    "        psth_mid_stem = np.std(np.concatenate(psth_all[idx_mid]), axis=0) / np.sqrt(len(idx_mid))\n",
    "        psth_mid_odd = np.nanmean(np.concatenate(psth_all[idx_odd_mid]), axis=0)\n",
    "        psth_mid_even = np.nanmean(np.concatenate(psth_all[idx_even_mid]), axis=0)\n",
    "\n",
    "        psth_end = np.nanmean(np.concatenate(psth_all[idx_end]), axis=0)\n",
    "        psth_end_stem = np.std(np.concatenate(psth_all[idx_end]), axis=0) / np.sqrt(len(idx_end))\n",
    "        psth_end_odd = np.nanmean(np.concatenate(psth_all[idx_odd_end]), axis=0)\n",
    "        psth_end_even = np.nanmean(np.concatenate(psth_all[idx_even_end]), axis=0)\n",
    "\n",
    "        key_ROI1[i_roi].psth_first = psth_first\n",
    "        key_ROI1[i_roi].psth_first_stem = psth_first_stem\n",
    "        key_ROI1[i_roi].psth_first_odd = psth_first_odd\n",
    "        key_ROI1[i_roi].psth_first_even = psth_first_even\n",
    "\n",
    "        key_ROI1[i_roi].psth_begin = psth_begin\n",
    "        key_ROI1[i_roi].psth_begin_stem = psth_begin_stem\n",
    "        key_ROI1[i_roi].psth_begin_odd = psth_begin_odd\n",
    "        key_ROI1[i_roi].psth_begin_even = psth_begin_even\n",
    "\n",
    "        key_ROI1[i_roi].psth_mid = psth_mid\n",
    "        key_ROI1[i_roi].psth_mid_stem = psth_mid_stem\n",
    "        key_ROI1[i_roi].psth_mid_odd = psth_mid_odd\n",
    "        key_ROI1[i_roi].psth_mid_even = psth_mid_even\n",
    "\n",
    "        key_ROI1[i_roi].psth_end = psth_end\n",
    "        key_ROI1[i_roi].psth_end_stem = psth_end_stem\n",
    "        key_ROI1[i_roi].psth_end_odd = psth_end_odd\n",
    "        key_ROI1[i_roi].psth_end_even = psth_end_even\n",
    "\n",
    "        key_ROI3[i_roi].psth_first = psth_first\n",
    "        key_ROI3[i_roi].psth_first_stem = psth_first_stem\n",
    "        key_ROI3[i_roi].psth_first_odd = psth_first_odd\n",
    "        key_ROI3[i_roi].psth_first_even = psth_first_even\n",
    "\n",
    "        key_ROI3[i_roi].psth_begin = psth_begin\n",
    "        key_ROI3[i_roi].psth_begin_stem = psth_begin_stem\n",
    "        key_ROI3[i_roi].psth_begin_odd = psth_begin_odd\n",
    "        key_ROI3[i_roi].psth_begin_even = psth_begin_even\n",
    "\n",
    "        key_ROI3[i_roi].psth_mid = psth_mid\n",
    "        key_ROI3[i_roi].psth_mid_stem = psth_mid_stem\n",
    "        key_ROI3[i_roi].psth_mid_odd = psth_mid_odd\n",
    "        key_ROI3[i_roi].psth_mid_even = psth_mid_even\n",
    "\n",
    "        key_ROI3[i_roi].psth_end = psth_end\n",
    "        key_ROI3[i_roi].psth_end_stem = psth_end_stem\n",
    "        key_ROI3[i_roi].psth_end_odd = psth_end_odd\n",
    "        key_ROI3[i_roi].psth_end_even = psth_end_even\n",
    "\n",
    "        # Stability\n",
    "        r = np.corrcoef([psth_first_odd.flatten(), psth_first_even.flatten()], rowvar=False)\n",
    "        key_ROI4[i_roi].psth_first_odd_vs_even_corr = r[0, 1]\n",
    "\n",
    "        r = np.corrcoef([psth_begin_odd.flatten(), psth_begin_even.flatten()], rowvar=False)\n",
    "        key_ROI4[i_roi].psth_begin_odd_vs_even_corr = r[0, 1]\n",
    "\n",
    "        r = np.corrcoef([psth_mid_odd.flatten(), psth_mid_even.flatten()], rowvar=False)\n",
    "        key_ROI4[i_roi].psth_mid_odd_vs_even_corr = r[0, 1]\n",
    "\n",
    "        r = np.corrcoef([psth_end_odd.flatten(), psth_end_even.flatten()], rowvar=False)\n",
    "        key_ROI4[i_roi].psth_end_odd_vs_even_corr = r[0, 1]\n",
    "\n",
    "        # Between conditions\n",
    "        r = np.corrcoef([psth_first.flatten(), psth_begin.flatten()], rowvar=False)\n",
    "        key_ROI4[i_roi].psth_first_vs_begin_corr = r[0, 1]\n",
    "\n",
    "        r = np.corrcoef([psth_first.flatten(), psth_mid.flatten()], rowvar=False)\n",
    "        key_ROI4[i_roi].psth_first_vs_mid_corr = r[0, 1]\n",
    "\n",
    "        r = np.corrcoef([psth_first.flatten(), psth_end.flatten()], rowvar=False)\n",
    "        key_ROI4[i_roi].psth_first_vs_end_corr = r[0, 1]\n",
    "\n",
    "        r = np.corrcoef([psth_begin.flatten(), psth_end.flatten()], rowvar=False)\n",
    "        key_ROI4[i_roi].psth_begin_vs_end_corr = r[0, 1]\n",
    "\n",
    "        r = np.corrcoef([psth_begin.flatten(), psth_mid.flatten()], rowvar=False)\n",
    "        key_ROI4[i_roi].psth_begin_vs_mid_corr = r[0, 1]\n",
    "\n",
    "        r = np.corrcoef([psth_mid.flatten(), psth_end.flatten()], rowvar=False)\n",
    "        key_ROI4[i_roi].psth_mid_vs_end_corr = r[0, 1]\n",
    "\n",
    "        _, idx_peak_first = np.max(psth_first)\n",
    "        key_ROI4[i_roi].peaktime_psth_first = time[idx_peak_first]\n",
    "        _, idx_peak_begin = np.max(psth_begin)\n",
    "        key_ROI4[i_roi].peaktime_psth_begin = time[idx_peak_begin]\n",
    "        _, idx_peak_mid = np.max(psth_mid)\n",
    "        key_ROI4[i_roi].peaktime_psth_mid = time[idx_peak_mid]\n",
    "        _, idx_peak_end = np.max(psth_end)\n",
    "        key_ROI4[i_roi].peaktime_psth_end = time[idx_peak_end]\n",
    "\n",
    "        # Single trials, averaged across all time duration in a specific time interval (e.g., after the licport onset (t>=0))\n",
    "        idx_onset = (time >= fr_interval_limit[0]) & (time < fr_interval_limit[1])\n",
    "        temp = np.concatenate(psth_all[idx_first], axis=0)\n",
    "        psth_first_trials = np.nanmean(temp[:, idx_onset], axis=1)\n",
    "        temp = np.concatenate(psth_all[idx_begin], axis=0)\n",
    "        psth_begin_trials = np.nanmean(temp[:, idx_onset], axis=1)\n",
    "        temp = np.concatenate(psth_all[idx_mid], axis=0)\n",
    "        psth_mid_trials = np.nanmean(temp[:, idx_onset], axis=1)\n",
    "        temp = np.concatenate(psth_all[idx_end], axis=0)\n",
    "        psth_end_trials = np.nanmean(temp[:, idx_onset], axis=1)\n",
    "\n",
    "        key_ROI4[i_roi].block_mean_first = np.nanmean(psth_first_trials)\n",
    "        key_ROI4[i_roi].block_mean_begin = np.nanmean(psth_begin_trials)\n",
    "        key_ROI4[i_roi].block_mean_mid = np.nanmean(psth_mid_trials)\n",
    "        key_ROI4[i_roi].block_mean_end = np.nanmean(psth_end_trials)\n",
    "\n",
    "        p, _ = scipy.stats.ranksums(psth_first_trials, psth_begin_trials)\n",
    "        key_ROI4[i_roi].block_mean_pval_first_begin = p\n",
    "        p, _ = scipy.stats.ranksums(psth_first_trials, psth_end_trials)\n",
    "        key_ROI4[i_roi].block_mean_pval_first_end = p\n",
    "        p, _ = scipy.stats.ranksums(psth_begin_trials, psth_end_trials)\n",
    "        key_ROI4[i_roi].block_mean_pval_begin_end = p\n",
    "\n",
    "        # At peak response time\n",
    "        temp = np.concatenate(psth_all[idx_first], axis=0)\n",
    "        psth_first_trials_peak = temp[:, idx_peak_first]\n",
    "        temp = np.concatenate(psth_all[idx_begin], axis=0)\n",
    "        psth_begin_trials_peak = temp[:, idx_peak_begin]\n",
    "        temp = np.concatenate(psth_all[idx_mid], axis=0)\n",
    "        psth_mid_trials_peak = temp[:, idx_peak_mid]\n",
    "        temp = np.concatenate(psth_all[idx_end], axis=0)\n",
    "        psth_end_trials_peak = temp[:, idx_peak_end]\n",
    "\n",
    "        key_ROI4[i_roi].block_peak_first = np.nanmean(psth_first_trials_peak)\n",
    "        key_ROI4[i_roi].block_peak_begin = np.nanmean(psth_begin_trials_peak)\n",
    "        key_ROI4[i_roi].block_peak_mid = np.nanmean(psth_mid_trials_peak)\n",
    "        key_ROI4[i_roi].block_peak_end = np.nanmean(psth_end_trials_peak)\n",
    "\n",
    "        p, _ = scipy.stats.ranksums(psth_first_trials_peak, psth_begin_trials_peak)\n",
    "        key_ROI4[i_roi].block_peak_pval_first_begin = p\n",
    "        p, _ = scipy.stats.ranksums(psth_first_trials_peak, psth_end_trials_peak)\n",
    "        key_ROI4[i_roi].block_peak_pval_first_end = p\n",
    "        p, _ = scipy.stats.ranksums(psth_begin_trials_peak, psth_end_trials_peak)\n",
    "        key_ROI4[i_roi].block_peak_pval_begin_end = p\n",
    "\n",
    "        # k2=key_ROI4[i_roi]\n",
    "        # insert(self4, k2)\n",
    "       \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "  \n",
    "    # Inserting bulk data into tables\n",
    "    self.insert(key_ROI1)  \n",
    "    self2.insert(key_ROI2)  \n",
    "\n",
    "    try:\n",
    "        # Insert into key_ROI3 table\n",
    "        self3.insert(key_ROI3) \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "    # Insert into key_ROI4 table\n",
    "        self4.insert(key_ROI4)  \n",
    "    except:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
